{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f4056ea-3b52-4664-bc62-fde3c0872afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def copy_group(src, dst):\n",
    "    for key in src.keys():\n",
    "        if isinstance(src[key], h5py.Group):\n",
    "            dst.create_group(key)\n",
    "            copy_group(src[key], dst[key])\n",
    "        else:\n",
    "            src.copy(key, dst)\n",
    "\n",
    "def split_data(input_path, output_path, levels=1, max_samples=100000, max_length=100, min_length=3):\n",
    "    with h5py.File(input_path, 'r') as f:\n",
    "        with h5py.File(output_path + '_train.h5', 'w') as f_80, h5py.File(output_path + '_test.h5', 'w') as f_20:\n",
    "            copy_group(f['graph'], f_80.create_group('graph'))\n",
    "            copy_group(f['graph'], f_20.create_group('graph'))\n",
    "            f_80.create_group('trajectories')\n",
    "            f_20.create_group('trajectories')\n",
    "    \n",
    "            all_trajectories = {}\n",
    "            for k in f['trajectories']:\n",
    "                if levels == 1:\n",
    "                    edge_idx = tuple(f[f'trajectories/{k}/edge_idxs'][:])\n",
    "                    if len(edge_idx) < min_length or len(edge_idx) > max_length or edge_idx in all_trajectories:\n",
    "                        continue\n",
    "                    all_trajectories[edge_idx] = k\n",
    "                    if len(all_trajectories) > max_samples:\n",
    "                        break\n",
    "                else:\n",
    "                    for k2 in f[f'trajectories/{k}']:\n",
    "                        edge_idx = tuple(f[f'trajectories/{k}/{k2}/edge_idxs'][:])\n",
    "                        if len(edge_idx) < min_length or len(edge_idx) > max_length or edge_idx in all_trajectories:\n",
    "                            continue\n",
    "                        all_trajectories[edge_idx] = (k, k2)\n",
    "                        if len(all_trajectories) > max_samples:\n",
    "                            break\n",
    "    \n",
    "            # Randomly shuffle the trajectories\n",
    "            dict_keys = list(all_trajectories.keys())\n",
    "            random.shuffle(dict_keys)\n",
    "    \n",
    "            split_point = int(0.8 * len(dict_keys))\n",
    "    \n",
    "            # split and copy the data\n",
    "            for i, edge_idx in enumerate(dict_keys):\n",
    "                k = all_trajectories[edge_idx]\n",
    "                if i < split_point:\n",
    "                    dst_file = f_80\n",
    "                else:\n",
    "                    dst_file = f_20\n",
    "\n",
    "                if levels > 1:\n",
    "                    k1, k2 = k\n",
    "                    src_path = f'trajectories/{k1}/{k2}'\n",
    "                    if k1 not in dst_file['trajectories']:\n",
    "                        dst_file['trajectories'].create_group(k1)\n",
    "                    copy_group(f[src_path], dst_file[f'trajectories/{k1}'].create_group(k2))\n",
    "                else:\n",
    "                    src_path = f'trajectories/{k}'\n",
    "                    copy_group(f[src_path], dst_file[f'trajectories'].create_group(k))\n",
    "    \n",
    "    print(\"Splitting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5de357c-339e-4249-a059-30f28078cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete.\n"
     ]
    }
   ],
   "source": [
    "split_data('/ceph/hdd/students/yaro/new_format/geolife.h5', '../datasets/geolife', levels=1, max_samples=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a191a702-293a-4f0d-9669-2f24da4fd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete.\n"
     ]
    }
   ],
   "source": [
    "split_data('/ceph/hdd/students/yaro/new_format/tdrive.h5', '../datasets/tdrive', levels=1, max_samples=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a031ae-5ded-48aa-acc3-054c624a2dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting complete.\n"
     ]
    }
   ],
   "source": [
    "split_data('/ceph/hdd/students/yaro/pneuma/merged.h5', '../datasets/pneuma', levels=2, max_samples=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a9c733-ea2c-4463-88a5-47a7d60d6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from datasets import GeoLifeTrajectoryDataset, TDriveTrajectoryDataset, PneumaTrajectoryDataset, Distance_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521df46a-094d-43de-a903-450fbf2ccc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13869, 3468)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = GeoLifeTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/geolife_train.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "testdata = GeoLifeTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/geolife_test.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "\n",
    "len(data), len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1f0f5fc-51eb-424b-8c41-cce70d13b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 1433)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TDriveTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/tdrive_train.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "testdata = TDriveTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/tdrive_test.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "\n",
    "len(data), len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87666c67-33df-49c0-8aff-4cd61cf6fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8216, 2060)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = PneumaTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/pneuma_train.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "testdata = PneumaTrajectoryDataset(\"/ceph/hdd/students/weea/trajectory-prediction-on-graphs/datasets/pneuma_test.h5\", n_samples=-1, min_trajectory_length=3, max_trajectory_length=10000)\n",
    "\n",
    "len(data), len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a8be6-4db3-4826-901b-9fadfc05542e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
